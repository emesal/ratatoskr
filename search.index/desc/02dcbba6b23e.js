rd_("AjContains the success valueCfModel identifier (e.g., \xe2\x80\x9call-MiniLM-L6-v2\xe2\x80\x9d, \xe2\x80\x9c\xe2\x80\xa6AkToken ID in the vocabulary.10AhContains the error valueAkNatural language inference.0CaEnd byte offset in the original text (exclusive).0BdLook up cached metadata for a model.AoGet metadata for a model by ID.DdReturns <code>true</code> if this set contains the given capability.BiNumber of entries currently in the cache.BbNumber of entries in the registry.BbMaximum allowed value (inclusive).AbSet maximum value.1BbMinimum allowed value (inclusive).AbSet minimum value.1CgCreate an empty cache with the default max capacity \xe2\x80\xa6C`Create a new cache from the given configuration.BdCreate a config with default values.CiCreate a new response cache with the given configuration.BkCreate a new config with sensible defaults.CgCreate a new EmbeddedGateway with the given registries.CgCreate a new HuggingFace client with the given API key.AlCreate a new empty registry.CnCreate a new zero-shot stance provider wrapping a classify \xe2\x80\xa6CnCreate a new latency tracker with the given EWMA smoothing \xe2\x80\xa6C`Create an empty routing config (no preferences).BfWrap a chat provider with retry logic.BlWrap an embedding provider with retry logic.BfWrap an NLI provider with retry logic.BjWrap a generate provider with retry logic.BjWrap a classify provider with retry logic.BhWrap a stance provider with retry logic.<CkCreate a new LlmChatProvider with the given backend and \xe2\x80\xa6AiCreate an empty registry.BhCreate options with the specified model.BkCreate new model info with required fields.AfCreate an empty range.2AcCreate a new token.AcNLI provider names.AoSet the preferred NLI provider.AlPreferred NLI provider name.BhSet the time-to-live for cached entries.CcTime-to-live for cached entries. Default: 24 hours.1CaTime-to-live for cached entries. Default: 1 hour.AoURL to fetch the registry from.BeLegacy bare string (just a model ID).AnMulti-turn chat conversations.0AdGeneration complete.oStream complete01AmRole of a message participant0AeText chunk generated.0CeLog a warning and proceed without the unsupported \xe2\x80\xa60BiChat completion using the fallback chain.AdChat provider names.AnNon-streaming chat completion.B`Set the preferred chat provider.AmPreferred chat provider name.AmNon-streaming chat completionAoReturns the argument unchanged.0000000000000000000000000000000000000000000000000000000000000000000000000000000AiAll capabilities enabled.AhBasic model information.0BaCalls <code>U::from(self)</code>.0000000000000000000000000000000000000000000000000000000000000000000000000000000CfReturns an iterator over the capabilities in this set.B`List all model metadata entries.BdProvider name for logging/debugging.00000CdSeed for deterministic generation (where supported).BfSet seed for deterministic generation.1oGenerated text.BaText representation of the token.10AoTool types for function callingAeCreate a user messageA`Text embeddings.0CbReturn an <code>UnsupportedParameter</code> error.0BfText expresses support for the target.0BaModel is loaded and ready to use.0BaA single token from tokenization.0BmUsage statistics (typically at end of stream)AgToken usage statistics.10AmSmoothing factor (0.0\xe2\x80\x931.0).AbBuild the gateway.AbCaching subsystem.AbEvict all entries.BfTotal number of observations recorded.BfGenerate embeddings for a single text.BdEmbed text using the fallback chain.BeGenerate embedding for a single text.BeSet the preferred embedding provider.BbPreferred embedding provider name.AlGenerate embeddings for textAeRatatoskr error typesBdScore for favor stance (0.0 to 1.0).0BlThe determined stance label (highest score).0CnMerge a single entry: update existing parameters or insert \xe2\x80\xa6CbMerges two capability sets using union (OR) logic.BhModel ID the rejection was observed for.ClThe actual model identifier (prefix stripped if provider \xe2\x80\xa6BjModel to use for zero-shot classification.BmThe model identifier this preset resolves to.AnThe resolved model identifier.AlModel to use for generation.AjModel used for generation.10BcModel information and status types.CiSet the retry configuration for transient error handling.ChRetry configuration, delay calculation, and provider \xe2\x80\xa6BgStart byte offset in the original text.0BeToken types for tokenization results.CgTop-k sampling: only consider the k most likely tokens.AcSet top-k sampling.1AkNucleus sampling threshold.jSet top_p.1BcPublic types for the Ratatoskr API.AhToken usage information.0CfProvider-specific parameter not in the well-known set.0CjSilently ignore unsupported parameters (legacy behaviour).0BmParameter exists but constraints are unknown.0BjResult type alias for Ratatoskr operationsAaStance detection.0DeCanonical string representation matching <code>ChatOptions</code>/\xe2\x80\xa6BcConfigure Google (Gemini) provider.DgInsert (or overwrite) metadata, keyed on <code>metadata.info.id</code>.CkInsert a model entry, replacing any existing entry with \xe2\x80\xa6BbInserts a capability into the set.AiEnable or disable jitter.CfWhether to add random jitter to delays. Default: true.AgModel metadata entries.0BjConfigure Ollama provider with custom URL.BaConfigure direct OpenAI provider.CiLook up a preset entry for the given tier and capability.CnPreset entry types: model ID + optional default generation \xe2\x80\xa6CdHuman-readable reason (typically the error message).AjReason for unavailability.0AmRecord a parameter rejection.BfRecord a request duration observation.ClRemote model registry \xe2\x80\x94 fetch, cache, and load curated \xe2\x80\xa6AfStance provider names.BlSet the preferred stance detection provider.BiPreferred stance detection provider name.AgStance detection types.AgCreate a system messageCbThe target topic that stance was measured against.0AgCore ModelGateway traitChProvider traits for capability-specific implementations.BhText expresses opposition to the target.0AbText content chunk0CeGit commit SHA at build time, or \xe2\x80\x9cunknown\xe2\x80\x9d if \xe2\x80\xa6CnTrait for types that have a provider name. Implemented for \xe2\x80\xa6B`Model is currently being loaded.0nA chat message0BjConsumer can set this freely within range.0CcText is neutral or does not express a clear stance.0AnTool/function calling support.0BoAdd an NLI provider (appended to end of chain).BfScore for against stance (0.0 to 1.0).0AlGet the text content, if anyDjCurrent EWMA latency estimate, or <code>None</code> if no observations \xe2\x80\xa6CaCreate a new builder for configuring the gateway.BiBuilder for configuring gateway instancesChConversions between ratatoskr types and llm crate types.BoDefault value if not specified by the consumer.0AgGateway implementationsAlLook up a cached NLI result.BjCheck if any NLI providers are registered.CkPer-provider EWMA latency tracking, keyed by provider name.BdMessage types for chat conversationsBfScore for neutral stance (0.0 to 1.0).0BdChat options and configuration typesAgAutoconfig presets: \xe2\x80\xa60CkAutoconfig presets (empty if not present or legacy format).AdPricing information.0AoSet preferred provider routing.CkRouting configuration, latency tracking, and cost-aware \xe2\x80\xa6BoSet default timeout for all requests (seconds).AmFormat version (currently 1).BoVersion information with embedded git metadata.AiZero-shot classification.0AlSingle-turn text generation.0BeValue is fixed by the provider/model.0AmA tool call made by the model0BoAdd a chat provider (appended to end of chain).CgGet the byte length of this token in the original text.BaPerform zero-shot classification.AnClassification provider names.BjSet the preferred classification provider.BgPreferred classification provider name.CgCreate a config that disables retries (single attempt).CmEmbeddedGateway - wraps the ProviderRegistry for embedded \xe2\x80\xa6BiText generation using the fallback chain.AhGenerate provider names.AnNon-streaming text generation.BkSet the preferred text generation provider.BhPreferred text generation provider name.AmNon-streaming text generationC`Types for text generation (non-chat) operations.BkCheck if any chat providers are registered.AkWhether the cache is empty.AnWhether the registry is empty.AnTrue if no parameters are set.CcLLM crate wrapper implementing ChatProvider and \xe2\x80\xa6FiProvider that rejected it (e.g. <code>&quot;openrouter&quot;</code>, <code>&quot;anthropic&quot;</code>).CnIf set, skip the fallback chain and route to this provider \xe2\x80\xa6nProvider name.ClProvider name (e.g., \xe2\x80\x9cfastembed\xe2\x80\x9d, \xe2\x80\x9chuggingface\xe2\x80\x9d, \xe2\x80\xa60CnModel registry \xe2\x80\x94 centralised model metadata with layered \xe2\x80\xa6C`Provider registry with fallback chain semantics.CcOpt-in response cache for deterministic operations.BbResponse and streaming event typesCmTokenize text into detailed Token objects with IDs, text, \xe2\x80\xa6CiCreate a config with a custom URL and default cache path.BeModel is available and can be loaded.0BdEvents emitted during streaming chat0A`Embedding result0BeInformation about an available model.0jNLI result0C`Main entry point for creating gateway instances.0CeReasoning/thinking content (extended thinking models)0BdConfigure direct Anthropic provider.AkCreate an assistant messageChCompute a cache key from operation, model, and input \xe2\x80\xa6CkChat-capable gateway (chat, streaming, generate, tool use).CgOverride the runtime parameter discovery configuration.BbRuntime parameter discovery cache.AiEmbedding provider names.DgCreate metadata from a <code>ModelInfo</code> with empty parameter map.CaWhether the working tree was dirty at build time.BcPerform natural language inference.BcInfer NLI using the fallback chain.CnInfer entailment/contradiction/neutral between premise and \xe2\x80\xa6AjNatural language inferenceCcInference result types for embeddings, NLI, and \xe2\x80\xa6CbCheck if the model is usable (ready or available).BfSet the maximum delay between retries.ClMaximum delay between retries (caps exponential growth). \xe2\x80\xa6AgThe rejected parameter.CaParameter metadata types for model introspection.BjProvider implementations for capabilities.BnRatatoskr - Unified model gateway for LLM APIsCeReasoning configuration for extended thinking models.AlSet reasoning configuration.1AjShort (7-char) commit SHA.B`Telemetry metric name constants.BnSet the name field (for multi-agent scenarios)CjGit branch at build time, or \xe2\x80\x9cunknown\xe2\x80\x9d if unavailable.CjThread-safe ephemeral store for provider-fetched model \xe2\x80\xa6BmA single model entry from the OpenRouter API.BmAccept both versioned and bare-array formats.AiTool choice configuration0BoFull preset with model and optional parameters.CaAdd a stance provider (appended to end of chain).CjCollect all unique provider names across all capabilities.CeExtract just the date (YYYY-MM-DD) from the build \xe2\x80\xa6BfLocal path to cache the registry JSON.BlEmbedding dimensions (for embedding models).0CcExtra fields to merge into the request body via \xe2\x80\xa6BmCheck if any stance providers are registered.AkInsert a cached NLI result.BkLocal inference only (no API calls needed).BeMaximum number of tokens to generate.oSet max tokens.1CkSet the Ollama base URL (only relevant for Ollama backend).BnOllama base URL (only used for Ollama backend)CfConfigure OpenRouter provider (routes to many models).DkOptional preset parameters, <code>None</code> for bare entries or empty \xe2\x80\xa6BlOptional default parameters for this preset.BkPer-parameter availability and constraints.0CkSave registry data to the local cache (atomic write via \xe2\x80\xa6BaInsert or update a single preset.BbParameter validation policy types.BlExecute an async operation with retry logic.BeConfiguration for the response cache.BmOptions for chat requests (provider-agnostic)0AjRuntime status of a model.0BhProvider for natural language inference.B`Package version from Cargo.toml.CnA single preset: model ID with optional default generation \xe2\x80\xa6CjPricing information for a model (cost per million tokens).0AmRate limited by the provider.CfConfiguration for retry behaviour on transient errors.AjThe detected stance label.0ClA tool call\xe2\x80\x99s arguments are complete (does NOT end the \xe2\x80\xa60BjTop provider info from the OpenRouter API.AgModel is not available.0BiParameter is not supported by this model.0BhStreaming chat using the fallback chain.AjStreaming chat completion.AiStreaming chat completionBgGenerate embeddings for multiple texts.BnEmbed batch of texts using the fallback chain.BoGenerate embeddings for multiple texts (batch).AjBatch embedding generationCgEWMA of request duration in microseconds, stored as \xe2\x80\xa6BnCreate a stance result from individual scores.BhShared HTTP client for metadata fetches.CkConfigure HuggingFace provider for embeddings, NLI, and \xe2\x80\xa6CmHuggingFace Inference API client for embeddings, NLI, and \xe2\x80\xa6CaList all available models and their capabilities.BdLoad cached registry data from disk.BiSet the maximum number of cached entries.BgMaximum cached entries. Default: 1,000.1CbMaximum number of cached entries. Default: 10,000.AiMerge a batch of entries.DkFor <code>RateLimited</code> errors, the duration the provider suggests \xe2\x80\xa6CiSampling temperature (0.0 to 2.0). Higher values make \xe2\x80\xa6A`Set temperature.1AlCreate a tool result messageBkCreate an unavailable status with a reason.CkProvider-specific translation layer for parameters that \xe2\x80\xa6BnArchitecture metadata from the OpenRouter API.BeWhat capabilities a gateway supports.0AmProvider for multi-turn chat.AkNon-streaming chat response0BcReason the model stopped generating0ChThe core gateway trait that all implementations must \xe2\x80\xa6CmPricing from the OpenRouter API (string-encoded decimals, \xe2\x80\xa6AkResult of stance detection.0AfTotal tokens consumed.CiAdd a classification provider (appended to end of chain).CcAdd a generate provider (appended to end of chain).ClDeserialized for forward compatibility; not yet surfaced \xe2\x80\xa6BlStreaming backpressure via bounded channels.AiWhat can this gateway do?BaCapabilities this model supports.0AlGateway capability reportingAnCount tokens for a given modelCkExtract text content from a message, returning an error \xe2\x80\xa6BfFetch registry data from a remote URL.CeCheck if any classification providers are registered.BoCheck if any generate providers are registered.ClWhether this parameter is supported (anything other than \xe2\x80\xa6CgWhether this error is transient and the request may \xe2\x80\xa6ClList all configured presets as a tier \xe2\x86\x92 capability set \xe2\x80\xa6CeSet maximum attempts (including the initial request).CkMaximum number of attempts (including the initial request).BcGet the status of a specific model.CiConvenience: set the remote registry URL with default \xe2\x80\xa6AkSet the timeout in seconds.AjDefault timeout in secondsAhSet pricing information.AiStreaming chat responses.0BlRaw JSON seed data compiled into the binary.BkEvents emitted during streaming generation.0ClExtended model metadata including parameter availability \xe2\x80\xa60BdCentralised model metadata registry.AmPrefix for preset model URIs.DcWell-known parameter names with a <code>Custom</code> escape hatch.0CaProvider names per capability, in priority order.ChTotal retry attempts (not counting the initial request).CfResult of parsing a model string \xe2\x80\x94 may include a \xe2\x80\xa6CfIn-memory response cache for deterministic operations.BbPreferred provider per capability.AjToken counting for models.0AoIncremental tool call arguments0AdStart of a tool call0CeAdd an embedding provider (appended to end of chain).DbApply a <code>RoutingConfig</code> to reorder the fallback chains.BjOptional cache control directive (e.g. \xe2\x80\xa60CkCombined cost per million tokens (prompt + completion), \xe2\x80\xa6AbSet default value.B`When the rejection was recorded.DcCompute a cache key from <code>(provider, model, parameter)</code>.AjReason generation stopped.0AkLook up a cached embedding.C`Check if any embedding providers are registered.BjSet the base delay before the first retry.CbBase delay before the first retry. Default: 500ms.CgMerge incoming presets (incoming overrides existing \xe2\x80\xa6CjParse a registry payload, accepting both versioned and \xe2\x80\xa6CdResolve a model string, handling two prefix schemes:AkAdd a single stop sequence.Ck<code>ToString::to_string</code>, but without panic on OOM.0ClCreate a client with a custom base URL (for testing with \xe2\x80\xa6CkCached response value \xe2\x80\x94 either an embedding or an NLI \xe2\x80\xa6AoZero-shot classification result0BfLocal inference (no API calls needed).0CbMessage content (extensible for future multimodal)0CeOpenRouter <code>/api/v1/models</code> list response.BjNumeric range constraints for a parameter.0BoTotal requests dispatched through the registry.AeRatatoskr error typesCiVersioned payload wrapper for the remote registry format.AmResponse format configuration0AnProvider for stance detection.BdTool definition for function calling0CdWrap a stream in a bounded channel for backpressure.CnBuild an llm provider configured for the given options and \xe2\x80\xa6BlMaximum context window in tokens (if known).0CnFetch metadata for a model from this provider\xe2\x80\x99s upstream \xe2\x80\xa6BeConvert llm crate usage to our formatCiWrap an NLI provider in retry decorator if config is set.CjGet extended metadata for a model, including parameter \xe2\x80\xa6CiList all registered provider names per capability (in \xe2\x80\xa6ClRecord request outcome metrics (counter + histogram) and \xe2\x80\xa6ChResolve a preset for the given cost tier and capability.CnOpt-in response cache for deterministic operations (embed, \xe2\x80\xa6CgEnable the response cache for deterministic operations.1CmReturns the list of parameters that are set (not None) in \xe2\x80\xa60BgSequences where generation should stop.AcSet stop sequences.1AnHuman-readable version string.AlAdd a parameter declaration.CcBuild timestamp (RFC 3339), or \xe2\x80\x9cunknown\xe2\x80\x9d if \xe2\x80\xa6C`Configuration for the parameter discovery cache.CaA single parameter rejection observed at runtime.ChGateway that wraps a ProviderRegistry for embedded mode.0AlOptions for text generation.0CkWraps llm crate provider configuration to implement our \xe2\x80\xa6CaA capability that a model or gateway may support.0CkPer-provider latency tracker using exponential weighted \xe2\x80\xa6CdReasoning configuration for extended thinking models0AfReasoning effort level0C`Parsed registry data: models + optional presets.CjReturn all preset tiers and their capability names (no \xe2\x80\xa6BjStance detection using the fallback chain.BdDetect stance toward a target topic.BgStance detection toward a target topic.CgRuntime parameter discovery cache (records provider \xe2\x80\xa6CfCalculate the effective delay, respecting provider \xe2\x80\xa6CcStreaming text generation using the fallback chain.AjStreaming text generation.AiStreaming text generationBmBatch NLI inference using the fallback chain.AdBatch NLI inference.CiBatch NLI inference \xe2\x80\x94 more efficient for multiple pairsCiWrap a chat provider in retry decorator if config is set.CgOverride the base URL for the models metadata endpoint.ChOverride base URL for model metadata endpoint (testing).AkParse the arguments as JSONBfSet the remote registry configuration.BjConvert our messages to llm crate messagesBnFetch remote registry and save to local cache.AoAdd a capability to this model.AmSet the embedding dimensions.BnTotal cache hits (for response cache, task 9).BkProvider for zero-shot text classification.BnDefault base URL for HuggingFace Inference APIBiProvider for single-turn text generation.AnResponse from text generation.0CcDefault generation parameters attached to a preset.CkResult of resolving a preset: the concrete model ID and \xe2\x80\xa6CiCost information for a provider serving a specific model.CdRegistry of providers with fallback chain semantics.BjBuilder for configuring gateway instances.0CbHuggingFace API capabilities (embeddings, NLI, \xe2\x80\xa6AjInsert a cached embedding.CbReturn all active (non-expired) discovery records.BmMerge parameter overrides into this metadata.ClPenalise tokens based on whether they appear in the text \xe2\x80\xa6AeSet presence penalty.1B`Get all presets for a cost tier.DhGet the EWMA latency tracker for a provider, or <code>None</code> if \xe2\x80\xa6AlSet the retry configuration.ClWarn about preset model IDs that aren\xe2\x80\x99t present in the \xe2\x80\xa6CgCreate a new LlmChatProvider with a shared HTTP client.BjCreate a cache with a custom max capacity.AmProvider for text embeddings.BeClient for HuggingFace Inference API.CgProvider cannot handle this model (wrong model, RAM \xe2\x80\xa6CkCalculate the delay for a given attempt number (0-indexed).CfPenalise tokens based on frequency in the text so far.AfSet frequency penalty.1CbCheck if at least one chat provider is configured.CeMaximum output tokens (distinct from context window).0CkWrap a stance provider in retry decorator if config is set.BfTotal number of observations recorded.BoOpenRouter model metadata types and conversion.CfDefault generation parameters from the preset, if any.CkReorder a provider vec so the named provider is at index 0.CmReturn chat providers sorted cheapest-first for the given \xe2\x80\xa6BdSet the parameter validation policy.BbGet the current validation policy.C`Total cache misses (for response cache, task 9).CbZero-shot classification using the fallback chain.BoZero-shot classification with candidate labels.AhZero-shot classificationDbDefault cache path: <code>~/.cache/ratatoskr/registry.json</code>.C`Record token usage metrics from a chat response.BlSet the stream buffer size for backpressure.CeSet a cache control directive for this tool (e.g. \xe2\x80\xa6ChLoad cached remote registry data and merge into this \xe2\x80\xa6CnCreate a latency tracker with the default smoothing factor \xe2\x80\xa6CjCreate a registry pre-populated with the embedded seed \xe2\x80\xa6ChAdjustments computed by the workarounds module for a \xe2\x80\xa6DbDecorator that wraps an <code>NliProvider</code> with retry logic.DgBuild a patched <code>ChatOptions</code> when the resolved model or \xe2\x80\xa6DcMap OpenRouter <code>supported_parameters</code> strings to our \xe2\x80\xa6CgCompute provider-specific adjustments for the given \xe2\x80\xa6CkFetch model metadata from the chat provider fallback chain.CgFind a specific provider by name in a capability chain.BjConvert llm crate tool calls to our formatCkCheck cache for multiple texts, returning hits and miss \xe2\x80\xa6DfConvert an OpenRouter model entry into our <code>ModelMetadata</code>.ChWhether an error should trigger fallback to the next \xe2\x80\xa6ClWrap a classify provider in retry decorator if config is \xe2\x80\xa6ClWrap a generate provider in retry decorator if config is \xe2\x80\xa6CgMerge cached hits with provider results for a batch \xe2\x80\xa6BjSet the runtime parameter discovery cache.AlSet the context window size.BlDefault URL for the curated remote registry.BfConfiguration for the remote registry.DbDecorator that wraps a <code>ChatProvider</code> with retry logic.ChParameter is not supported by the target model/provider.CjFetch metadata from the provider that would serve this \xe2\x80\xa6AmFilter entries by capability.DfCheck whether a specific <code>(provider, model, parameter)</code> \xe2\x80\xa6CnWrap an embedding provider in retry decorator if config is \xe2\x80\xa6BoCost per million prompt tokens (USD), if known.BkCost per million prompt/input tokens (USD).0CbValidate parameters for a chat request against \xe2\x80\xa6CiDefault number of items buffered between producer and \xe2\x80\xa6BjMaximum supported registry format version.BmHow a parameter is exposed for a given model.0BdSet the parameter validation policy.DdDecorator that wraps a <code>StanceProvider</code> with retry logic.DgWrapper that implements <code>StanceProvider</code> using zero-shot \xe2\x80\xa6CoApply these parameters as defaults to <code>ChatOptions</code>.CjEnsure a latency tracker exists for the given provider \xe2\x80\xa6CcCheck response status and map to appropriate error.BjInsert multiple embeddings into the cache.BlSet the stream buffer size for backpressure.AjSet maximum output tokens.CkDefault maximum number of entries in the model metadata \xe2\x80\xa6C`In-memory cache of runtime parameter rejections.DkBuild a patched <code>GenerateOptions</code> when the resolved model or \xe2\x80\xa6ChCheck if at least one capability provider is configured.AlRequest duration in seconds.DfDecorator that wraps a <code>ClassifyProvider</code> with retry logic.DfDecorator that wraps a <code>GenerateProvider</code> with retry logic.CcCost per million completion tokens (USD), if known.C`Cost per million completion/output tokens (USD).0CiDisable automatic background registry refresh at startup.DbBatch query: return the subset of <code>params</code> that are \xe2\x80\xa6CfValidate parameters for a generate request against \xe2\x80\xa6CaHow to handle unsupported parameters in requests.0DhDecorator that wraps an <code>EmbeddingProvider</code> with retry logic.BkCreate an assistant message with tool callsCdParameters this provider supports for chat requests.DcApply these parameters as defaults to <code>GenerateOptions</code>.ClNative parallel tool use flag (for backends like mistral \xe2\x80\xa6CiRecord a runtime parameter rejection in the discovery \xe2\x80\xa6CdTotal parameter discoveries from runtime rejections.BmDisable runtime parameter discovery entirely.BnParse OpenRouter per-token price string to \xe2\x80\xa6ChParameters this provider supports for generate requests.")